{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "811efbcb",
   "metadata": {},
   "source": [
    "# MNIST Digits Recognition Pipeline\n",
    "\n",
    "This notebook contains a Kubeflow Pipeline for training a CNN model on the MNIST digits dataset.\n",
    "\n",
    "## Workflow Steps:\n",
    "### 1. **Setup** (Run First)\n",
    "- **Download MNIST Dataset**: Downloads MNIST data and uploads it to your MinIO bucket\n",
    "\n",
    "### 2. **Pipeline Components**:\n",
    "- **get_data_batch**: Downloads MNIST data from MinIO and saves training/test datasets\n",
    "- **get_latest_data**: Dummy component for demonstration\n",
    "- **reshape_data**: Reshapes and normalizes the image data for CNN training\n",
    "- **model_building**: Builds, trains, and evaluates a CNN model using Keras/TensorFlow\n",
    "- **model_serving**: Deploys the trained model using KServe\n",
    "\n",
    "## Usage:\n",
    "1. **First**: Run cell 2 to download and upload MNIST dataset to MinIO\n",
    "2. Run cell 3 to compile the pipeline\n",
    "3. Upload the generated YAML file to your Kubeflow UI\n",
    "4. Create a run with desired parameters (epochs, optimizer)\n",
    "\n",
    "## Requirements:\n",
    "- MinIO server running at 34.28.94.159:9000\n",
    "- MinIO bucket \"mlpipeline\" (will be created automatically)\n",
    "- KServe installed in the cluster\n",
    "- Service account \"sa-minio-kserve\" configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9319df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Download and upload MNIST dataset to MinIO\n",
    "def download_and_upload_mnist():\n",
    "    \"\"\"\n",
    "    Download MNIST dataset and upload it to MinIO bucket\n",
    "    \"\"\"\n",
    "    print(\"üîÑ Downloading MNIST dataset...\")\n",
    "    \n",
    "    try:\n",
    "        # Import required libraries\n",
    "        from tensorflow import keras\n",
    "        import numpy as np\n",
    "        from minio import Minio\n",
    "        import tempfile\n",
    "        import os\n",
    "        \n",
    "        # Load MNIST dataset using Keras\n",
    "        print(\"üì• Loading MNIST from Keras datasets...\")\n",
    "        (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "        \n",
    "        print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "        print(f\"   - x_train shape: {x_train.shape}\")\n",
    "        print(f\"   - y_train shape: {y_train.shape}\")\n",
    "        print(f\"   - x_test shape: {x_test.shape}\")\n",
    "        print(f\"   - y_test shape: {y_test.shape}\")\n",
    "        \n",
    "        # Save as npz file\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            mnist_file = os.path.join(temp_dir, \"mnist.npz\")\n",
    "            np.savez(mnist_file, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
    "            print(f\"üíæ Saved dataset to temporary file: {mnist_file}\")\n",
    "            \n",
    "            # Connect to MinIO\n",
    "            print(\"üì¶ Connecting to MinIO...\")\n",
    "            minio_client = Minio(\n",
    "                \"34.28.94.159:9000\",\n",
    "                access_key=\"minio\",\n",
    "                secret_key=\"minio123\",\n",
    "                secure=False\n",
    "            )\n",
    "            \n",
    "            bucket_name = \"mlpipeline\"\n",
    "            \n",
    "            # Create bucket if it doesn't exist\n",
    "            if not minio_client.bucket_exists(bucket_name):\n",
    "                print(f\"üìÅ Creating bucket '{bucket_name}'...\")\n",
    "                minio_client.make_bucket(bucket_name)\n",
    "            \n",
    "            # Upload the file\n",
    "            print(\"‚¨ÜÔ∏è Uploading mnist.npz to MinIO...\")\n",
    "            minio_client.fput_object(bucket_name, \"mnist.npz\", mnist_file)\n",
    "            \n",
    "            print(\"‚úÖ MNIST dataset uploaded successfully to MinIO!\")\n",
    "            \n",
    "            # Verify upload\n",
    "            stat = minio_client.stat_object(bucket_name, \"mnist.npz\")\n",
    "            print(f\"üìä Uploaded file size: {stat.size} bytes\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading/uploading MNIST: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "print(\"üìã Run this cell first to prepare your MinIO bucket with the MNIST dataset:\")\n",
    "print(\"This will download the MNIST dataset and upload it to your MinIO server.\")\n",
    "print(\"After running this, your pipeline will have the required mnist.npz file.\")\n",
    "print(\"\\nüîÑ Execute the function below:\")\n",
    "\n",
    "# Uncomment the line below to run the upload\n",
    "# download_and_upload_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da13c87-aed3-4c3a-bac8-1807ded41b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/e5076f7c-8815-4eb9-81e2-223e31a65748\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/ff09ee4c-feac-4d47-b2eb-d177b7696c00\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "# Creating a ML pipeline with the MNIST digits dataset\n",
    "# KFP Example with lightweight Python components\n",
    "#\n",
    "\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "import kfp.components as components\n",
    "from typing import NamedTuple\n",
    "\n",
    "def get_data_batch() -> NamedTuple('Outputs', [('datapoints_training', float),('datapoints_test', float),('dataset_version', str)]):\n",
    "    \"\"\"\n",
    "    Function to get dataset and load it to minio bucket\n",
    "    \"\"\"\n",
    "    print(\"getting data\")\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    import json\n",
    "\n",
    "    minio_client = Minio(\n",
    "        \"34.28.94.159:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"mlpipeline\"\n",
    "    \n",
    "    minio_client.fget_object(minio_bucket,\"mnist.npz\",\"/tmp/mnist.npz\")\n",
    "    \n",
    "    def load_data():\n",
    "        with np.load(\"/tmp/mnist.npz\", allow_pickle=True) as f:\n",
    "            x_train, y_train = f[\"x_train\"], f[\"y_train\"]\n",
    "            x_test, y_test = f[\"x_test\"], f[\"y_test\"]\n",
    "\n",
    "        return (x_train, y_train), (x_test, y_test)\n",
    "    \n",
    "    # Get MNIST data directly from library\n",
    "    (x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "    # save to numpy file, store in Minio\n",
    "    np.save(\"/tmp/x_train.npy\",x_train)\n",
    "    minio_client.fput_object(minio_bucket,\"x_train\",\"/tmp/x_train.npy\")\n",
    "\n",
    "    np.save(\"/tmp/y_train.npy\",y_train)\n",
    "    minio_client.fput_object(minio_bucket,\"y_train\",\"/tmp/y_train.npy\")\n",
    "\n",
    "    np.save(\"/tmp/x_test.npy\",x_test)\n",
    "    minio_client.fput_object(minio_bucket,\"x_test\",\"/tmp/x_test.npy\")\n",
    "\n",
    "    np.save(\"/tmp/y_test.npy\",y_test)\n",
    "    minio_client.fput_object(minio_bucket,\"y_test\",\"/tmp/y_test.npy\")\n",
    "    \n",
    "    dataset_version = \"1.0\"\n",
    "    \n",
    "    print(f\"x_train shape: {x_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "    print(f\"x_test shape: {x_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    divmod_output = namedtuple('Outputs', ['datapoints_training', 'datapoints_test', 'dataset_version'])\n",
    "    return divmod_output(float(x_train.shape[0]),float(x_test.shape[0]),dataset_version)\n",
    "\n",
    "def get_latest_data():\n",
    "    \"\"\"\n",
    "    Dummy functions for showcasing\n",
    "    \"\"\"\n",
    "    print(\"Adding latest data\")\n",
    "\n",
    "def reshape_data():\n",
    "    \"\"\"\n",
    "    Reshape the data for model building\n",
    "    \"\"\"\n",
    "    print(\"reshaping data\")\n",
    "    \n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "\n",
    "    minio_client = Minio(\n",
    "        \"34.28.94.159:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"mlpipeline\"\n",
    "    \n",
    "    # load data from minio\n",
    "    minio_client.fget_object(minio_bucket,\"x_train\",\"/tmp/x_train.npy\")\n",
    "    x_train = np.load(\"/tmp/x_train.npy\")\n",
    "    \n",
    "    minio_client.fget_object(minio_bucket,\"x_test\",\"/tmp/x_test.npy\")\n",
    "    x_test = np.load(\"/tmp/x_test.npy\")\n",
    "    \n",
    "    # reshaping the data\n",
    "    # reshaping pixels in a 28x28px image with greyscale, canal = 1. This is needed for the Keras API\n",
    "    x_train = x_train.reshape(-1,28,28,1)\n",
    "    x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "    # normalizing the data\n",
    "    # each pixel has a value between 0-255. Here we divide by 255, to get values from 0-1\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    \n",
    "    # save data from minio\n",
    "    np.save(\"/tmp/x_train.npy\",x_train)\n",
    "    minio_client.fput_object(minio_bucket,\"x_train\",\"/tmp/x_train.npy\")\n",
    "    \n",
    "    np.save(\"/tmp/x_test.npy\",x_test)\n",
    "    minio_client.fput_object(minio_bucket,\"x_test\",\"/tmp/x_test.npy\")\n",
    "\n",
    "def model_building(\n",
    "    no_epochs: int = 1,\n",
    "    optimizer: str = \"adam\"\n",
    ") -> NamedTuple('Output', [('model_accuracy', float), ('model_loss', float)]):\n",
    "    \"\"\"\n",
    "    Build the model with Keras API\n",
    "    Export model parameters\n",
    "    \"\"\"\n",
    "    from tensorflow import keras\n",
    "    import tensorflow as tf\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    import json\n",
    "    \n",
    "    minio_client = Minio(\n",
    "        \"34.28.94.159:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"mlpipeline\"\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(10, activation='softmax')) #output are 10 classes, numbers from 0-9\n",
    "\n",
    "    #compile the model - we want to have a binary outcome\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    minio_client.fget_object(minio_bucket,\"x_train\",\"/tmp/x_train.npy\")\n",
    "    x_train = np.load(\"/tmp/x_train.npy\")\n",
    "    \n",
    "    minio_client.fget_object(minio_bucket,\"y_train\",\"/tmp/y_train.npy\")\n",
    "    y_train = np.load(\"/tmp/y_train.npy\")\n",
    "    \n",
    "    #fit the model and return the history while training\n",
    "    history = model.fit(\n",
    "      x=x_train,\n",
    "      y=y_train,\n",
    "      epochs=no_epochs,\n",
    "      batch_size=20,\n",
    "    )\n",
    "    \n",
    "    minio_client.fget_object(minio_bucket,\"x_test\",\"/tmp/x_test.npy\")\n",
    "    x_test = np.load(\"/tmp/x_test.npy\")\n",
    "    \n",
    "    minio_client.fget_object(minio_bucket,\"y_test\",\"/tmp/y_test.npy\")\n",
    "    y_test = np.load(\"/tmp/y_test.npy\")\n",
    "    \n",
    "\n",
    "    # Test the model against the test dataset\n",
    "    model_loss, model_accuracy = model.evaluate(x=x_test,y=y_test)\n",
    "    \n",
    "    print(f\"Model accuracy: {model_accuracy}\")\n",
    "    print(f\"Model loss: {model_loss}\")\n",
    "    \n",
    "    ### Save model to minIO\n",
    "    keras.models.save_model(model,\"/tmp/detect-digits\")\n",
    "    \n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    def upload_local_directory_to_minio(local_path, bucket_name, minio_path):\n",
    "        assert os.path.isdir(local_path)\n",
    "\n",
    "        for local_file in glob.glob(local_path + '/**'):\n",
    "            local_file = local_file.replace(os.sep, \"/\")\n",
    "            if not os.path.isfile(local_file):\n",
    "                upload_local_directory_to_minio(\n",
    "                    local_file, bucket_name, minio_path + \"/\" + os.path.basename(local_file))\n",
    "            else:\n",
    "                remote_path = os.path.join(\n",
    "                    minio_path, local_file[1 + len(local_path):])\n",
    "                remote_path = remote_path.replace(\n",
    "                    os.sep, \"/\")\n",
    "                minio_client.fput_object(bucket_name, remote_path, local_file)\n",
    "\n",
    "    upload_local_directory_to_minio(\"/tmp/detect-digits\",minio_bucket,\"models/detect-digits/1/\")\n",
    "    \n",
    "    print(\"Saved model to minIO\")\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    output = namedtuple('Output', ['model_accuracy', 'model_loss'])\n",
    "    return output(float(model_accuracy), float(model_loss))\n",
    "\n",
    "def model_serving():\n",
    "    \"\"\"\n",
    "    Create kserve instance\n",
    "    \"\"\"\n",
    "    from kubernetes import client \n",
    "    from kserve import KServeClient\n",
    "    from kserve import constants\n",
    "    from kserve import utils\n",
    "    from kserve import V1beta1InferenceService\n",
    "    from kserve import V1beta1InferenceServiceSpec\n",
    "    from kserve import V1beta1PredictorSpec\n",
    "    from kserve import V1beta1TFServingSpec\n",
    "    from datetime import datetime\n",
    "\n",
    "    namespace = utils.get_default_target_namespace()\n",
    "\n",
    "    now = datetime.now()\n",
    "    v = now.strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "\n",
    "    name='digits-recognizer-{}'.format(v)\n",
    "    kserve_version='v1beta1'\n",
    "    api_version = constants.KSERVE_GROUP + '/' + kserve_version\n",
    "\n",
    "    isvc = V1beta1InferenceService(api_version=api_version,\n",
    "                                   kind=constants.KSERVE_KIND,\n",
    "                                   metadata=client.V1ObjectMeta(\n",
    "                                       name=name, namespace=namespace, annotations={'sidecar.istio.io/inject':'false'}),\n",
    "                                   spec=V1beta1InferenceServiceSpec(\n",
    "                                   predictor=V1beta1PredictorSpec(\n",
    "                                       service_account_name=\"sa-minio-kserve\",\n",
    "                                       tensorflow=(V1beta1TFServingSpec(\n",
    "                                           storage_uri=\"s3://mlpipeline/models/detect-digits/\"))))\n",
    "    )\n",
    "\n",
    "    KServe = KServeClient()\n",
    "    KServe.create(isvc)\n",
    "\n",
    "# Create component ops\n",
    "comp_get_data_batch = components.create_component_from_func(\n",
    "    get_data_batch,\n",
    "    base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\",\n",
    "    packages_to_install=[\"minio\"]\n",
    ")\n",
    "\n",
    "comp_get_latest_data = components.create_component_from_func(\n",
    "    get_latest_data,\n",
    "    base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\"\n",
    ")\n",
    "\n",
    "comp_reshape_data = components.create_component_from_func(\n",
    "    reshape_data,\n",
    "    base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\",\n",
    "    packages_to_install=[\"minio\"]\n",
    ")\n",
    "\n",
    "comp_model_building = components.create_component_from_func(\n",
    "    model_building,\n",
    "    base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\",\n",
    "    packages_to_install=[\"minio\"]\n",
    ")\n",
    "\n",
    "comp_model_serving = components.create_component_from_func(\n",
    "    model_serving,\n",
    "    base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\",\n",
    "    packages_to_install=['kserve==0.11.0', 'kubernetes']\n",
    ")\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='digits-recognizer-pipeline',\n",
    "    description='Detect digits'\n",
    ")\n",
    "def digits_recognizer_pipeline(no_epochs: int = 1, optimizer: str = \"adam\"):\n",
    "    step1_1 = comp_get_data_batch()\n",
    "    step1_2 = comp_get_latest_data()\n",
    "    \n",
    "    step2 = comp_reshape_data()\n",
    "    step2.after(step1_1, step1_2)\n",
    "    \n",
    "    step3 = comp_model_building(no_epochs=no_epochs, optimizer=optimizer)\n",
    "    step3.after(step2)\n",
    "    \n",
    "    step4 = comp_model_serving()\n",
    "    step4.after(step3)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Compile pipeline\n",
    "    kfp.compiler.Compiler().compile(\n",
    "        pipeline_func=digits_recognizer_pipeline,\n",
    "        package_path='digits_recognizer_pipeline.yaml'\n",
    "    )\n",
    "    print(\"Pipeline compiled successfully to 'digits_recognizer_pipeline.yaml'\")\n",
    "    \n",
    "    # Optional: Create and run pipeline if client is available\n",
    "    try:\n",
    "        client = kfp.Client()\n",
    "        \n",
    "        # Submit pipeline run\n",
    "        run = client.create_run_from_pipeline_func(\n",
    "            digits_recognizer_pipeline,\n",
    "            arguments={\n",
    "                \"no_epochs\": 1,\n",
    "                \"optimizer\": \"adam\"\n",
    "            },\n",
    "            experiment_name=\"digits-recognizer\"\n",
    "        )\n",
    "        \n",
    "        print(f\"Pipeline run submitted: {run.run_id}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not submit run automatically: {e}\")\n",
    "        print(\"You can upload the compiled YAML file manually to the Kubeflow UI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36057a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the pipeline\n",
    "print(\"Compiling pipeline...\")\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=digits_recognizer_pipeline,\n",
    "    package_path='digits_recognizer_pipeline.yaml'\n",
    ")\n",
    "print(\"‚úÖ Pipeline compiled successfully to 'digits_recognizer_pipeline.yaml'\")\n",
    "print(\"\\nYou can now:\")\n",
    "print(\"1. Upload the YAML file to your Kubeflow Pipelines UI\")\n",
    "print(\"2. Create a new run with parameters:\")\n",
    "print(\"   - no_epochs: Number of training epochs (default: 1)\")\n",
    "print(\"   - optimizer: Optimizer to use (default: 'adam')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Try to submit pipeline run (only works when running inside Kubeflow)\n",
    "import os\n",
    "\n",
    "try:\n",
    "    client = kfp.Client()\n",
    "    \n",
    "    # Test connection\n",
    "    experiments = client.list_experiments()\n",
    "    print(\"‚úÖ Connected to Kubeflow Pipelines!\")\n",
    "    \n",
    "    # Submit pipeline run\n",
    "    run = client.create_run_from_pipeline_func(\n",
    "        digits_recognizer_pipeline,\n",
    "        arguments={\n",
    "            \"no_epochs\": 1,\n",
    "            \"optimizer\": \"adam\"\n",
    "        },\n",
    "        experiment_name=\"digits-recognizer\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Pipeline run submitted: {run.run_id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"‚ÑπÔ∏è  Could not connect to Kubeflow Pipelines automatically.\")\n",
    "    print(\"This is expected when running outside of a Kubeflow cluster.\")\n",
    "    \n",
    "    # Check if YAML file was created\n",
    "    if os.path.exists('digits_recognizer_pipeline.yaml'):\n",
    "        print(\"\\n‚úÖ Pipeline YAML file created successfully!\")\n",
    "        print(\"üìÅ File location: digits_recognizer_pipeline.yaml\")\n",
    "        print(\"\\nüìã Next steps:\")\n",
    "        print(\"1. Navigate to your Kubeflow Pipelines UI\")\n",
    "        print(\"2. Click 'Upload pipeline'\")\n",
    "        print(\"3. Select the 'digits_recognizer_pipeline.yaml' file\")\n",
    "        print(\"4. Create a new run with these parameters:\")\n",
    "        print(\"   - no_epochs: 1-10 (number of training epochs)\")\n",
    "        print(\"   - optimizer: 'adam', 'sgd', or 'rmsprop'\")\n",
    "        print(\"\\nüîß Make sure your cluster has:\")\n",
    "        print(\"   - MinIO with 'mlpipeline' bucket containing mnist.npz\")\n",
    "        print(\"   - KServe installed and configured\")\n",
    "        print(\"   - Service account 'sa-minio-kserve' with proper permissions\")\n",
    "    else:\n",
    "        print(\"‚ùå Pipeline YAML file was not created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Test MinIO connection and check bucket contents\n",
    "from minio import Minio\n",
    "import numpy as np\n",
    "\n",
    "def test_minio_connection():\n",
    "    \"\"\"Test MinIO connection and list bucket contents\"\"\"\n",
    "    try:\n",
    "        # Connect to MinIO\n",
    "        minio_client = Minio(\n",
    "            \"34.28.94.159:9000\",\n",
    "            access_key=\"minio\",\n",
    "            secret_key=\"minio123\",\n",
    "            secure=False\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ MinIO connection successful!\")\n",
    "        \n",
    "        # Check if bucket exists\n",
    "        bucket_name = \"mlpipeline\"\n",
    "        if minio_client.bucket_exists(bucket_name):\n",
    "            print(f\"‚úÖ Bucket '{bucket_name}' exists\")\n",
    "            \n",
    "            # List objects in bucket\n",
    "            objects = minio_client.list_objects(bucket_name, recursive=True)\n",
    "            print(f\"\\nüìÅ Objects in bucket '{bucket_name}':\")\n",
    "            \n",
    "            object_list = list(objects)\n",
    "            if object_list:\n",
    "                for obj in object_list:\n",
    "                    print(f\"  - {obj.object_name} (size: {obj.size} bytes)\")\n",
    "            else:\n",
    "                print(\"  (bucket is empty)\")\n",
    "                \n",
    "            # Check specifically for mnist.npz\n",
    "            try:\n",
    "                stat = minio_client.stat_object(bucket_name, \"mnist.npz\")\n",
    "                print(f\"\\n‚úÖ mnist.npz found! Size: {stat.size} bytes\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ùå mnist.npz not found: {e}\")\n",
    "                print(\"\\nüí° You need to upload mnist.npz to your MinIO bucket.\")\n",
    "                print(\"You can download it from: https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"‚ùå Bucket '{bucket_name}' does not exist\")\n",
    "            print(\"Please create the bucket first\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå MinIO connection failed: {e}\")\n",
    "        print(\"Please check:\")\n",
    "        print(\"1. MinIO server is running at 34.28.94.159:9000\")\n",
    "        print(\"2. Access credentials are correct\")\n",
    "        print(\"3. Network connectivity\")\n",
    "\n",
    "# Run the test\n",
    "test_minio_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165cb31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved get_data_batch function with error handling\n",
    "def get_data_batch_debug() -> tuple:\n",
    "    \"\"\"\n",
    "    Function to get dataset and load it to minio bucket - with debug info\n",
    "    \"\"\"\n",
    "    print(\"üîÑ Starting data download...\")\n",
    "    \n",
    "    try:\n",
    "        from minio import Minio\n",
    "        import numpy as np\n",
    "        import json\n",
    "        \n",
    "        print(\"üì¶ Connecting to MinIO...\")\n",
    "        minio_client = Minio(\n",
    "            \"34.28.94.159:9000\",\n",
    "            access_key=\"minio\",\n",
    "            secret_key=\"minio123\",\n",
    "            secure=False\n",
    "        )\n",
    "        minio_bucket = \"mlpipeline\"\n",
    "        \n",
    "        print(f\"‚úÖ Connected to MinIO server\")\n",
    "        \n",
    "        # Check if bucket exists\n",
    "        if not minio_client.bucket_exists(minio_bucket):\n",
    "            raise Exception(f\"Bucket '{minio_bucket}' does not exist!\")\n",
    "            \n",
    "        print(f\"‚úÖ Bucket '{minio_bucket}' exists\")\n",
    "        \n",
    "        # Check if mnist.npz exists\n",
    "        try:\n",
    "            stat = minio_client.stat_object(minio_bucket, \"mnist.npz\")\n",
    "            print(f\"‚úÖ mnist.npz found! Size: {stat.size} bytes\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå mnist.npz not found in bucket: {e}\")\n",
    "            \n",
    "            # List what's actually in the bucket\n",
    "            print(\"üìÅ Available files in bucket:\")\n",
    "            objects = list(minio_client.list_objects(minio_bucket, recursive=True))\n",
    "            if objects:\n",
    "                for obj in objects:\n",
    "                    print(f\"  - {obj.object_name}\")\n",
    "            else:\n",
    "                print(\"  (bucket is empty)\")\n",
    "            \n",
    "            raise Exception(\"mnist.npz file not found in MinIO bucket\")\n",
    "        \n",
    "        print(\"üì• Downloading mnist.npz...\")\n",
    "        minio_client.fget_object(minio_bucket, \"mnist.npz\", \"/tmp/mnist.npz\")\n",
    "        print(\"‚úÖ Download complete!\")\n",
    "        \n",
    "        def load_data():\n",
    "            with np.load(\"/tmp/mnist.npz\", allow_pickle=True) as f:\n",
    "                x_train, y_train = f[\"x_train\"], f[\"y_train\"]\n",
    "                x_test, y_test = f[\"x_test\"], f[\"y_test\"]\n",
    "            return (x_train, y_train), (x_test, y_test)\n",
    "        \n",
    "        print(\"üìä Loading data from downloaded file...\")\n",
    "        (x_train, y_train), (x_test, y_test) = load_data()\n",
    "        \n",
    "        print(f\"‚úÖ Data loaded successfully!\")\n",
    "        print(f\"   - x_train shape: {x_train.shape}\")\n",
    "        print(f\"   - y_train shape: {y_train.shape}\")\n",
    "        print(f\"   - x_test shape: {x_test.shape}\")\n",
    "        print(f\"   - y_test shape: {y_test.shape}\")\n",
    "        \n",
    "        return (x_train, y_train), (x_test, y_test)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in get_data_batch: {str(e)}\")\n",
    "        print(\"\\nüîß Troubleshooting steps:\")\n",
    "        print(\"1. Make sure MinIO server is running at 34.28.94.159:9000\")\n",
    "        print(\"2. Verify the 'mlpipeline' bucket exists\")\n",
    "        print(\"3. Upload mnist.npz to the bucket\")\n",
    "        print(\"4. Check network connectivity\")\n",
    "        raise e\n",
    "\n",
    "# Test the improved function\n",
    "try:\n",
    "    data = get_data_batch_debug()\n",
    "    print(\"üéâ Function test successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"üí• Function test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d18a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and upload MNIST dataset to MinIO\n",
    "def download_and_upload_mnist():\n",
    "    \"\"\"\n",
    "    Download MNIST dataset and upload it to MinIO bucket\n",
    "    \"\"\"\n",
    "    print(\"üîÑ Downloading MNIST dataset...\")\n",
    "    \n",
    "    try:\n",
    "        # Import required libraries\n",
    "        from tensorflow import keras\n",
    "        import numpy as np\n",
    "        from minio import Minio\n",
    "        import tempfile\n",
    "        import os\n",
    "        \n",
    "        # Load MNIST dataset using Keras\n",
    "        print(\"üì• Loading MNIST from Keras datasets...\")\n",
    "        (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "        \n",
    "        print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "        print(f\"   - x_train shape: {x_train.shape}\")\n",
    "        print(f\"   - y_train shape: {y_train.shape}\")\n",
    "        print(f\"   - x_test shape: {x_test.shape}\")\n",
    "        print(f\"   - y_test shape: {y_test.shape}\")\n",
    "        \n",
    "        # Save as npz file\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            mnist_file = os.path.join(temp_dir, \"mnist.npz\")\n",
    "            np.savez(mnist_file, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
    "            print(f\"üíæ Saved dataset to temporary file: {mnist_file}\")\n",
    "            \n",
    "            # Connect to MinIO\n",
    "            print(\"üì¶ Connecting to MinIO...\")\n",
    "            minio_client = Minio(\n",
    "                \"34.28.94.159:9000\",\n",
    "                access_key=\"minio\",\n",
    "                secret_key=\"minio123\",\n",
    "                secure=False\n",
    "            )\n",
    "            \n",
    "            bucket_name = \"mlpipeline\"\n",
    "            \n",
    "            # Create bucket if it doesn't exist\n",
    "            if not minio_client.bucket_exists(bucket_name):\n",
    "                print(f\"üìÅ Creating bucket '{bucket_name}'...\")\n",
    "                minio_client.make_bucket(bucket_name)\n",
    "            \n",
    "            # Upload the file\n",
    "            print(\"‚¨ÜÔ∏è Uploading mnist.npz to MinIO...\")\n",
    "            minio_client.fput_object(bucket_name, \"mnist.npz\", mnist_file)\n",
    "            \n",
    "            print(\"‚úÖ MNIST dataset uploaded successfully to MinIO!\")\n",
    "            \n",
    "            # Verify upload\n",
    "            stat = minio_client.stat_object(bucket_name, \"mnist.npz\")\n",
    "            print(f\"üìä Uploaded file size: {stat.size} bytes\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading/uploading MNIST: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Run this function to upload MNIST dataset\n",
    "try:\n",
    "    download_and_upload_mnist()\n",
    "    print(\"üéâ MNIST dataset is now available in your MinIO bucket!\")\n",
    "except Exception as e:\n",
    "    print(f\"üí• Failed to upload MNIST dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test existing model from MinIO\n",
    "def test_existing_model():\n",
    "    \"\"\"\n",
    "    Download and test the existing model from MinIO\n",
    "    \"\"\"\n",
    "    print(\"üîÑ Testing existing model from MinIO...\")\n",
    "    \n",
    "    try:\n",
    "        from minio import Minio\n",
    "        from tensorflow import keras\n",
    "        import numpy as np\n",
    "        import tempfile\n",
    "        import os\n",
    "        \n",
    "        # Connect to MinIO\n",
    "        print(\"üì¶ Connecting to MinIO...\")\n",
    "        minio_client = Minio(\n",
    "            \"34.28.94.159:9000\",\n",
    "            access_key=\"minio\",\n",
    "            secret_key=\"minio123\",\n",
    "            secure=False\n",
    "        )\n",
    "        \n",
    "        bucket_name = \"mlpipeline\"\n",
    "        \n",
    "        # Check if model exists\n",
    "        try:\n",
    "            stat = minio_client.stat_object(bucket_name, \"models/detect-digits.h5\")\n",
    "            print(f\"‚úÖ Model found! Size: {stat.size} bytes\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Model not found: {e}\")\n",
    "            return\n",
    "        \n",
    "        # Download the model\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            model_file = os.path.join(temp_dir, \"detect-digits.h5\")\n",
    "            print(\"üì• Downloading model...\")\n",
    "            minio_client.fget_object(bucket_name, \"models/detect-digits.h5\", model_file)\n",
    "            \n",
    "            # Load the model\n",
    "            print(\"üß† Loading model...\")\n",
    "            model = keras.models.load_model(model_file)\n",
    "            \n",
    "            print(\"‚úÖ Model loaded successfully!\")\n",
    "            print(\"üìä Model summary:\")\n",
    "            model.summary()\n",
    "            \n",
    "            # Test with some dummy data if available\n",
    "            try:\n",
    "                # Load MNIST test data if available\n",
    "                (_, _), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "                \n",
    "                # Preprocess the data (same as in your pipeline)\n",
    "                x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "                \n",
    "                # Test on a small subset\n",
    "                test_subset = x_test[:100]\n",
    "                predictions = model.predict(test_subset)\n",
    "                \n",
    "                print(f\"‚úÖ Model prediction test successful!\")\n",
    "                print(f\"   - Test data shape: {test_subset.shape}\")\n",
    "                print(f\"   - Predictions shape: {predictions.shape}\")\n",
    "                print(f\"   - Sample prediction: {np.argmax(predictions[0])}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Could not test with MNIST data: {e}\")\n",
    "                print(\"Model loaded successfully but test data unavailable\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing model: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Test the existing model\n",
    "try:\n",
    "    test_existing_model()\n",
    "except Exception as e:\n",
    "    print(f\"üí• Model test failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
